{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f34d4707",
   "metadata": {},
   "source": [
    "В качестве модели для решения данной задачи была взята модель NaiveBayes в предположении, что ~80% данных, поступающих в модель, являются \"человеческим\" текстом.\n",
    "\n",
    "В качестве строк кода на языке python были взяты 2 репозитория: https://github.com/3b1b/manim (тренировочный) и https://github.com/openai/gym (тестовый). Брались все файлы с расширением py и все строчки кода оттуда (кроме комментариев и строчных констант).\n",
    "\n",
    "В качестве строк на \"человеческом\" языке были взяты файлы с расширениями txt и md из этих репозиториев.\n",
    "Однако, данных оттуда не хватило даже для того, чтобы модель отмечала строчки \"yield from range(number + 1, number + on_each_side + 1)\" и \"If the page range is larger than a given size, the whole range is not\" как строчки кода и \"человеческого\" языка соответственно.\n",
    "\n",
    "По этой причине были взяты также файлы с расширением txt (с сайта https://www.homeenglish.ru/Books.htm), содержащие некоторые литературные произведения, написанные на английском языке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90827ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB as NaiveBayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer as BoW\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc476b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# путь к файлу -> список из строк этого файла\n",
    "def read(path, code=True):\n",
    "    with open(path, 'r') as f:\n",
    "        try:\n",
    "            text = f.read()\n",
    "        except Exception:\n",
    "            print(path)\n",
    "            text = ''\n",
    "    if code:  # удаляем комментарии из нескольких строк и str из кода\n",
    "        text = re.sub(r\"'''(.|\\n)*'''\", '', text)\n",
    "        text = re.sub(r'\"\"\"(.|\\n)*\"\"\"', '', text)\n",
    "        text = re.sub(r\"'.*'\", '', text)\n",
    "        text = re.sub(r'\".*\"', '', text)\n",
    "    else:  # удаляем кавычки из \"человеческих\" текстов\n",
    "        text = re.sub(r'\"(.*)\"', r'\\1', text)\n",
    "    new_text = []\n",
    "    for line in text.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if code:  # удаляем однострочные комментарии из кода\n",
    "            pos = re.search('#', line)\n",
    "            if pos:\n",
    "                line = line[:pos.span()[0]]\n",
    "        if line:  # пустые строки не нужны\n",
    "            new_text.append(line)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6ecde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обходит всё внутри path, собирает строки кода и строки \"человеческого\" текста из файлов\n",
    "def get_corpuses(path):\n",
    "    code_corpus, text_corpus = [], []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            fullname = os.path.join(root, file)\n",
    "            if re.search(r'\\.py', file):\n",
    "                code_corpus.extend(read(fullname))\n",
    "            if re.search(r'\\.(txt|md)', file):\n",
    "                text_corpus.extend(read(fullname, code=False))\n",
    "    return code_corpus, text_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "663ebb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем текстовые данные\n",
    "train_code_corpus, train_text_corpus = get_corpuses(r'train_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2fbbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переводим текстовые данные в вектора\n",
    "vectorizer = BoW()\n",
    "X_train = vectorizer.fit_transform(train_code_corpus + train_text_corpus)\n",
    "y_train = np.array([1] * len(train_code_corpus) + [0] * len(train_text_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ea447e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=(0.8, 0.2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучаем NaiveBayes на полученных векторах\n",
    "nb = NaiveBayes(alpha=0.01, class_prior=(0.8, 0.2))\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3465ac7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверяем пример из файла с заданием\n",
    "test_code = \"yield from range(number + 1, number + on_each_side + 1)\"\n",
    "test_text =  \"If the page range is larger than a given size, the whole range is not\"\n",
    "nb.predict(vectorizer.transform([test_code, test_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df883b",
   "metadata": {},
   "source": [
    "На данном примере всё работает так, как ожидалось.\n",
    "\n",
    "Теперь протестируем модель на большем количестве примеров.\n",
    "\n",
    "Количество примеров взято так, чтобы было ~80% \"человеческого\" текста в тренировочной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d00a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные для тестирования (в текстовом виде)\n",
    "test_code_corpus, test_text_corpus = get_corpuses(r'test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "750099c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.516010978956999\n",
      "4.051377586037847\n"
     ]
    }
   ],
   "source": [
    "# соотношения количества строк текстовых данных к количеству строк в коде\n",
    "print(len(train_text_corpus) / len(train_code_corpus))\n",
    "print(len(test_text_corpus) / len(test_code_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f02587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9936578404946884\n",
      "Recall: 0.6144720070595157\n"
     ]
    }
   ],
   "source": [
    "# Проверка качества модели\n",
    "X_test = vectorizer.transform(test_code_corpus + test_text_corpus)\n",
    "y_test = np.array([1] * len(test_code_corpus) + [0] * len(test_text_corpus))\n",
    "y_pred = nb.predict(X_test)\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_pred)\n",
    "print(f'Precision: {p[1]}')\n",
    "print(f'Recall: {r[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a6de24",
   "metadata": {},
   "source": [
    "Результаты тестирования говорят нам о том, что было выявлено всего около 60% строчек кода.\n",
    "\n",
    "При этом, если модель определила поданную ей на вход строку как строчку кода, то она с очень большой вероятностью (близкой к 1) определила верно.\n",
    "\n",
    "Модель не очень пригодна к полному использованию на практике, но благодаря её использованию можно перепроверять лишь только те строки, которые были классифицированы как \"человеческий\" текст, что сильно упрощает работу.\n",
    "\n",
    "Можно также поэкспериментировать с датасетами, на которых обучаем и тестируем модель (брать в качестве \"человеческого текста\" больше комментариев к коду, а не литературные произведения), и с различными векторизациями строчек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6c740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
